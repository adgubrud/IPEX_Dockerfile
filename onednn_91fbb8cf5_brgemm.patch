diff --git a/src/cpu/x64/brgemm/brgemm_types.hpp b/src/cpu/x64/brgemm/brgemm_types.hpp
index 8fad3da..b74b7d7 100644
--- a/src/cpu/x64/brgemm/brgemm_types.hpp
+++ b/src/cpu/x64/brgemm/brgemm_types.hpp
@@ -380,7 +380,7 @@ struct brgemm_kernel_params_t {
     size_t first_mb_matrix_addr_off;
     size_t dst_row_logical_off;
 
-    char *data_C_ptr_;
+    const char *data_C_ptr_;
 
     const void *a_zp_compensations = nullptr;
     const void *b_zp_compensations = nullptr;
@@ -478,7 +478,8 @@ struct brgemm_post_ops_data_t {
     brgemm_post_ops_data_t() = default;
     brgemm_post_ops_data_t(const void *bias, const float *scales,
             const void *binary_post_ops_rhs, size_t oc_logical_off,
-            const size_t dst_row_logical_off = 0, char *data_C_ptr_ = nullptr,
+            const size_t dst_row_logical_off = 0,
+            const char *data_C_ptr_ = nullptr,
             const size_t first_mb_matrix_addr_off = 0,
             const void *a_zp_compensations = nullptr,
             const void *b_zp_compensations = nullptr,
@@ -506,7 +507,7 @@ struct brgemm_post_ops_data_t {
     const void *binary_post_ops_rhs = nullptr;
     size_t oc_logical_off = 0;
     size_t dst_row_logical_off = 0;
-    char *data_C_ptr_ = nullptr;
+    const char *data_C_ptr_ = nullptr;
     size_t first_mb_matrix_addr_off = 0;
     const void *a_zp_compensations = nullptr;
     const void *b_zp_compensations = nullptr;
diff --git a/src/cpu/x64/brgemm/brgemm_utils.cpp b/src/cpu/x64/brgemm/brgemm_utils.cpp
index e281ac0..73adabe 100644
--- a/src/cpu/x64/brgemm/brgemm_utils.cpp
+++ b/src/cpu/x64/brgemm/brgemm_utils.cpp
@@ -82,8 +82,7 @@ namespace brgemm_utils {
 bool can_dispatch_uker(const brgemm_t *brg) {
     return brg->is_tmm
             && one_of(brg->type, brgemm_addr, brgemm_offs, brgemm_static_offs)
-            && brg->brgattr.use_uker
-            && !brg->brgattr.generate_skip_accumulation;
+            && brg->brgattr.use_uker;
 }
 
 void maybe_try_bf32(brgemm_t *brg) {
diff --git a/src/cpu/x64/brgemm/jit_brgemm_amx_uker.cpp b/src/cpu/x64/brgemm/jit_brgemm_amx_uker.cpp
index 3c0cbbe..6d24262 100644
--- a/src/cpu/x64/brgemm/jit_brgemm_amx_uker.cpp
+++ b/src/cpu/x64/brgemm/jit_brgemm_amx_uker.cpp
@@ -132,6 +132,7 @@ private:
 
     const reg64_t reg_stride_ld_block = rdx;
     const reg64_t reg_do_post_ops = rbx;
+    const reg64_t reg_do_skip_accum = reg_do_post_ops;
     const reg64_t reg_tmp_gpr = rbx;
     const reg64_t reg_ptr_sum_scale = rbx;
 
@@ -272,6 +273,7 @@ private:
         dim_iteration_t rdi;
         brgemm_iteration_t *prev_iter = nullptr;
         bool apply_postops = false;
+        bool skip_accumulation = false;
         brgemm_iteration_t() = default;
     };
 
@@ -1022,7 +1024,8 @@ void jit_brgemm_amx_uker_base_t::prefetching(
     if (brg.prfC.dist1 >= 0) {
         bool is_pfo_bi = false;
         brgemm_iteration_t pfo_bi;
-        if (use_ils_ && get_store_by_vectors(bi.apply_postops)) {
+        if (use_ils_ && !bi.skip_accumulation
+                && get_store_by_vectors(bi.apply_postops)) {
             if (was_prev_bi_ && brg.prfC.dist1 == 0) {
                 is_pfo_bi = true;
                 pfo_bi = prev_bi_;
@@ -1037,7 +1040,8 @@ void jit_brgemm_amx_uker_base_t::prefetching(
     if (brg.prfC.dist2 >= 0) {
         bool is_pfo_bi = false;
         brgemm_iteration_t pfo_bi;
-        if (use_ils_ && get_store_by_vectors(bi.apply_postops)) {
+        if (use_ils_ && !bi.skip_accumulation
+                && get_store_by_vectors(bi.apply_postops)) {
             if (was_prev_bi_ && brg.prfC.dist2 == 0) {
                 is_pfo_bi = true;
                 pfo_bi = prev_bi_;
@@ -1070,7 +1074,8 @@ void jit_brgemm_amx_uker_base_t::prefetching(
 void jit_brgemm_amx_uker_base_t::process_output_range(brgemm_iteration_t &bi,
         int bd_start, int bd_finish, int bd_inp_bdb, int bdb, int ldb) {
 
-    const auto wsp_offset = (use_ils_ || brg.interleave_tilestores_)
+    const auto wsp_offset = ((use_ils_ && !bi.skip_accumulation)
+                                    || brg.interleave_tilestores_)
             ? (bdb * prev_bi_.ldi.block2() + ldb) * prev_bi_.bdi.block(0)
                     * ld_block_C_size_
             : 0;
@@ -1095,8 +1100,12 @@ void jit_brgemm_amx_uker_base_t::process_output_range(brgemm_iteration_t &bi,
                                             : accm(bd);
         some_bd_mask = true;
 
-        const auto buf_offset = bd * ld_block_C_size_;
-        vmovups(vreg_acc, ptr[reg_buf + buf_offset + wsp_offset]);
+        if (bi.skip_accumulation) {
+            vpxord(vreg_acc, vreg_acc, vreg_acc);
+        } else {
+            const auto buf_offset = bd * ld_block_C_size_;
+            vmovups(vreg_acc, ptr[reg_buf + buf_offset + wsp_offset]);
+        }
 
         const auto c_offset = C_offset(bd_out_bd, bi.ldi.pos(ldb));
         const auto ptr_C = EVEX_compress_addr(reg_C, c_offset);
@@ -1250,6 +1259,7 @@ void jit_brgemm_amx_uker_base_t::store_vector(
 void jit_brgemm_amx_uker_base_t::interleave_store(
         brgemm_iteration_t &bi, bool store_all) {
 
+    if (bi.skip_accumulation) return;
     if (!use_ils_) return;
     if (!was_prev_bi_) return;
     if (!get_store_by_vectors(prev_bi_.apply_postops)) return;
@@ -1340,7 +1350,8 @@ void jit_brgemm_amx_uker_base_t::store_accumulators(brgemm_iteration_t &bi) {
     prf1C.vec = 0;
     prf2C.vec = 0;
 
-    if (store_by_vectors && !use_ils_ && !prepare_post_ops_registers_once_)
+    if (store_by_vectors && !(use_ils_ && !bi.skip_accumulation)
+            && !prepare_post_ops_registers_once_)
         prepare_post_ops_registers(bi);
 
     for (int bdb = 0; bdb < bi.bdi.block2(); bdb++) {
@@ -1348,15 +1359,15 @@ void jit_brgemm_amx_uker_base_t::store_accumulators(brgemm_iteration_t &bi) {
 
         for (int ldb = 0; ldb < bi.ldi.block2(); ldb++) {
             if (store_by_vectors) {
-                if (!brg.interleave_tilestores_) {
-                    const auto wsp_offset = use_ils_
+                if (!brg.interleave_tilestores_ && !bi.skip_accumulation) {
+                    const auto wsp_offset = (use_ils_ && !bi.skip_accumulation)
                             ? (bdb * bi.ldi.block2() + ldb) * bi.bdi.block(0)
                                     * ld_block_C_size_
                             : 0;
                     tilestored(ptr[reg_buf + reg_stride_ld_block + wsp_offset],
                             Tmm(get_C_tensor(bi, bdb, ldb)));
                 }
-                if (use_ils_) continue;
+                if ((use_ils_ && !bi.skip_accumulation)) continue;
 
                 prepare_post_ops_registers_ldb(bi, ldb);
 
@@ -1514,7 +1525,9 @@ void jit_brgemm_amx_uker_base_t::maybe_tilestore(brgemm_iteration_t &bi,
         const bool store_by_vectors = get_store_by_vectors(bi.apply_postops);
         Tmm acc = Tmm(store_tensor_idx);
         if (store_by_vectors) {
-            const auto wsp_offset = (use_ils_ || brg.interleave_tilestores_)
+            if (bi.skip_accumulation) return;
+            const auto wsp_offset = ((use_ils_ && !bi.skip_accumulation)
+                                            || brg.interleave_tilestores_)
                     ? (bdb_idx * bi.ldi.block2() + ldb_idx) * bi.bdi.block(0)
                             * ld_block_C_size_
                     : 0;
@@ -1684,8 +1697,9 @@ void jit_brgemm_amx_uker_base_t::maybe_pre_process_data(brgemm_iteration_t &bi,
     const bool is_A = mk == matrix_A;
     auto &transform_buf = is_A ? transform_buf_map_A_ : transform_buf_map_B_;
 
-    const auto transform_offset
-            = use_ils_ ? brg.get_num_C_tiles() * tile_size : 0;
+    const auto transform_offset = (use_ils_ && !bi.skip_accumulation)
+            ? brg.get_num_C_tiles() * tile_size
+            : 0;
     const auto max_bdb2 = imap_.bdis[0].block2();
     const auto max_rdb = imap_.rdis.size();
     const auto matrix_a_offset = transform_offset;
@@ -1780,12 +1794,14 @@ void jit_brgemm_amx_uker_base_t::rdb_loop(brgemm_iteration_t &bi) {
 }
 
 void jit_brgemm_amx_uker_base_t::bs_loop_body(brgemm_iteration_t &bi) {
-    if (brg.brgattr.var_bs) {
-        set_A_B_matrices();
-        add(reg_aux1_batch, sizeof(brgemm_batch_element_t));
-        prefetcht0(ptr[reg_aux1_batch]);
-    } else {
-        set_A_B_matrices(bi.bsi.pos);
+    if (!bi.skip_accumulation) {
+        if (brg.brgattr.var_bs) {
+            set_A_B_matrices();
+            add(reg_aux1_batch, sizeof(brgemm_batch_element_t));
+            prefetcht0(ptr[reg_aux1_batch]);
+        } else {
+            set_A_B_matrices(bi.bsi.pos);
+        }
     }
 
     rdb_loop(bi);
@@ -1794,6 +1810,10 @@ void jit_brgemm_amx_uker_base_t::bs_loop_body(brgemm_iteration_t &bi) {
 void jit_brgemm_amx_uker_base_t::bs_loop(brgemm_iteration_t &bi) {
 
     load_accumulators(bi);
+    if (bi.skip_accumulation) {
+        store_accumulators(bi);
+        return;
+    }
 
     if (brg.brgattr.var_bs) {
         if (brg.alpha != 0.f) {
@@ -1991,7 +2011,7 @@ void jit_brgemm_amx_uker_base_t::fill_imap() {
 void jit_brgemm_amx_uker_base_t::init(brgemm_iteration_t &bi) {
     was_prev_bi_ = false;
 
-    if (brg.type == brgemm_static_offs) {
+    if (brg.type == brgemm_static_offs && !bi.skip_accumulation) {
         if (brg.layout == brgemm_row_major) {
             mov(reg_aux_A, ptr[param1 + GET_OFF(ptr_A)]);
             mov(reg_aux_B, ptr[param1 + GET_OFF(ptr_B)]);
@@ -1999,7 +2019,7 @@ void jit_brgemm_amx_uker_base_t::init(brgemm_iteration_t &bi) {
             mov(reg_aux_A, ptr[param1 + GET_OFF(ptr_B)]);
             mov(reg_aux_B, ptr[param1 + GET_OFF(ptr_A)]);
         }
-    } else if (brg.brgattr.max_bs == 1) {
+    } else if (brg.brgattr.max_bs == 1 && !bi.skip_accumulation) {
         assert(one_of(brg.type, brgemm_addr, brgemm_offs));
         if (brg.type == brgemm_addr) {
             if (brg.layout == brgemm_row_major) {
@@ -2070,6 +2090,7 @@ void jit_brgemm_amx_uker_base_t::init(brgemm_iteration_t &bi) {
                 zmm_lbound, zmm_ubound, reg_tmp_gpr, data_type::f32, brg.dt_d);
     }
 
+    if (bi.skip_accumulation) return;
     prf1A.pft = brgemm_kernel_prefetching_t::brgemm_prf1;
     prf1A.dist = brg.prfA.dist1;
     prf2A.pft = brgemm_kernel_prefetching_t::brgemm_prf2;
@@ -2164,6 +2185,20 @@ void jit_brgemm_amx_uker_base_t::generate() {
         cmp(reg_do_post_ops, 0);
         jz(label_store_without_post_ops, T_NEAR);
         bi.apply_postops = true;
+        if (brg.brgattr.generate_skip_accumulation) {
+            brgemm_iteration_t bi1;
+            mov(reg_do_skip_accum, ptr[param1 + GET_OFF(skip_accm)]);
+            cmp(reg_do_skip_accum, 0);
+            Label label_do_not_skip_acc;
+            jz(label_do_not_skip_acc, T_NEAR);
+
+            bi1.skip_accumulation = true;
+            bi1.apply_postops = true;
+            top_loop(bi1);
+            jmp(label_to_ret, T_NEAR);
+
+            L(label_do_not_skip_acc);
+        }
         top_loop(bi);
         if (non_postops_generate) jmp(label_to_ret, T_NEAR);
         transform_buf_map_A_.clear();
diff --git a/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp b/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp
index e2b9b9b..86f6ad8 100644
--- a/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp
+++ b/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp
@@ -1469,6 +1469,13 @@ void jit_brgemm_kernel_t<isa, Wmm>::store_accumulators(int bd_block2,
                                         vreg_acc, ptr[reg_buf + buf_offset]);
                             }
                         }
+
+                        if (apply_post_ops && brg.is_int8
+                                && (brg.req_s8s8_compensation
+                                        || has_zero_points)) {
+                            apply_compensation(adj_bd_block, 1, is_ld_tail);
+                        }
+
                         if (need_to_apply_alpha_beta)
                             apply_alpha_beta(adj_bd_block, 1, is_ld_tail);
 
